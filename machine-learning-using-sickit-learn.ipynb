{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":29926,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ranisamyuktha/machine-learning-using-sickit-learn?scriptVersionId=206067709\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\nprint(stats.mode([8, 9, 8, 7, 9, 6, 7, 6]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"KNN","metadata":{}},{"cell_type":"markdown","source":"# Task 1\nImport two modules sklearn.datasets, and sklearn.model_selection.\n\nLoad popular iris data set from sklearn.datasets module and assign it to variable iris.\n\nSplit iris.data into two sets names X_train and X_test. Also, split iris.target into two sets Y_train and Y_test.\n\nHint: Use train_test_split method from sklearn.model_selection; set random_state to 30 and perform stratified sampling.\nPrint the shape of X_train dataset.\n\nPrint the shape of X_test dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\niris = load_iris()\nX_train,X_test,Y_train,Y_test = train_test_split(iris.data,iris.target,random_state = 30,stratify = iris.target)\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 2\nImport required module from sklearn.neighbors\n\nFit K nearest neighbors model on X_train data and Y_train labels, with default parameters. Name the model as knn_clf.\n\nEvaluate the model accuracy on training data set and print it's score.\n\nEvaluate the model accuracy on testing data set and print it's score","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\niris = load_iris()\nX_train,X_test,Y_train,Y_test = train_test_split(iris.data,iris.target,random_state = 30,stratify = iris.target)\nknn_clf = KNeighborsClassifier().fit(X_train,Y_train)\nprint(knn_clf.score(X_train,Y_train))\nprint(knn_clf.score(X_test,Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 3\nFit multiple K nearest neighbors models on X_train data and Y_train labels with n_neighbors parameter value changing from 3 to 10.\n\nEvaluate each model accuracy on testing data set.\n\nHint: Make use of for loop\nPrint the n_neighbors value of the model with highest accuracy.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\niris = load_iris()\nX_train,X_test,Y_train,Y_test = train_test_split(iris.data,iris.target,random_state = 30,stratify = iris.target)\nbest_score = 0\nfor n_neighbors in range(3,10):\n    knn_clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n    knn_clf.fit(X_train,Y_train)\n    knn_clf.predict(X_test)\n    score = knn_clf.score(X_test,Y_test)\n    if score > best_score:\n        best_score = score\n        max_neighbor = n_neighbors\nprint(max_neighbor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Trees","metadata":{}},{"cell_type":"markdown","source":"# Task 1\n\nImport two modules sklearn.datasets, and sklearn.model_selection.\nImport numpy and set random seed to 100.\n\nLoad popular Boston dataset from sklearn.datasets module and assign it to variable boston.\n\nSplit boston.data into two sets names X_train and X_test. Also, split boston.target into two sets Y_train and Y_test.\n\nHint: Use train_test_split method from sklearn.model_selection; set random_state to 30.\nPrint the shape of X_train dataset.\n\nPrint the shape of X_test dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nnp.random.seed(100)\nboston = load_boston()\nX_train,X_test,Y_train,Y_test = train_test_split(boston.data,boston.target,random_state = 30)\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 2\nImport required module from sklearn.tree.\n\nBuild a Decision tree Regressor model from X_train set and Y_train labels, with default parameters. Name the model as dt_reg.\n\nEvaluate the model accuracy on training data set and print it's score.\n\nEvaluate the model accuracy on testing data set and print it's score.\n\nPredict the housing price for first two samples of X_test set and print them.(Hint : Use predict() function)","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nnp.random.seed(100)\nboston = load_boston()\nX_train,X_test,Y_train,Y_test = train_test_split(boston.data,boston.target,random_state = 30)\nfrom sklearn.tree import DecisionTreeRegressor\ndt_reg = DecisionTreeRegressor()\ndt_reg.fit(X_train,Y_train)\nprint(dt_reg.score(X_train,Y_train))\nprint(dt_reg.score(X_test,Y_test))\nprint(dt_reg.predict(X_test[0:2]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 3\nFit multiple Decision tree regressors on X_train data and Y_train labels with max_depth parameter value changing from 2 to 5.\n\nEvaluate each model accuracy on testing data set.\n\nHint: Make use of for loop\nPrint the max_depth value of the model with highest accuracy.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nnp.random.seed(100)\nboston = load_boston()\nX_train,X_test,Y_train,Y_test = train_test_split(boston.data,boston.target,random_state = 30)\nbest_score = 0\nfrom sklearn.tree import DecisionTreeRegressor\nfor max_depth in range(2,5):\n    dt_reg = DecisionTreeRegressor(max_depth = max_depth)\n    dt_reg.fit(X_train,Y_train)\n    dt_reg.predict(X_test)\n    score = dt_reg.score(X_test,Y_test)\n    if score > best_score:\n        best_score = score\n        max_depth = max_depth\nprint(max_depth)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  ENSEMBLE","metadata":{}},{"cell_type":"markdown","source":"# Task 1\nImport two modules sklearn.datasets, and sklearn.model_selection.\nImport numpy and set random seed to 100\n\nLoad popular Boston dataset from sklearn.datasets module and assign it to variable boston.\n\nSplit boston.data into two sets names X_train and X_test. Also, split boston.target into two sets Y_train and Y_test.\n\nHint: Use train_test_split method from sklearn.model_selection; set random_state to 30.\nPrint the shape of X_train dataset.\n\nPrint the shape of X_test dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nnp.random.seed(100)\nboston = load_boston()\nX_train,X_test,Y_train,Y_test = train_test_split(boston.data,boston.target,random_state = 30)\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 2\nImport required module from sklearn.ensemble.\n\nBuild a Random Forest Regressor model from X_train set and Y_train labels, with default parameters. Name the model as rf_reg.\n\nEvaluate the model accuracy on training data set and print it's score.\n\nEvaluate the model accuracy on testing data set and print it's score.\n\nPredict the housing price for first two samples of X_test set and print them.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nnp.random.seed(100)\nboston = load_boston()\nX_train,X_test,Y_train,Y_test = train_test_split(boston.data,boston.target,random_state = 30)\nfrom sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor()\nrf_reg.fit(X_train,Y_train)\nprint(rf_reg.score(X_train,Y_train))\nprint(rf_reg.score(X_test,Y_test))\nprint(rf_reg.predict(X_test[0:2]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 3\nBuild multiple Random forest regressor on X_train set and Y_train labels with max_depth parameter value changing from 3 to 5 and also setting n_estimators to one of 50, 100, 200 values.\n\nEvaluate each model accuracy on testing data set.\n\nHint: Make use of for loop\nPrint the max_depth and n_estimators values of the model with highest accuracy.\n\nNote: Print the parameter values in the form of tuple (a, b). a refers to max_depth value and b refers to n_estimators","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nnp.random.seed(100)\nboston = load_boston()\nX_train,X_test,Y_train,Y_test = train_test_split(boston.data,boston.target,random_state = 30)\nbest_score = 0\nfrom sklearn.ensemble import RandomForestRegressor\nfor max_depth  in range(3,6):\n    rf_reg = RandomForestRegressor(max_depth = max_depth,n_estimators = 100)\n    rf_reg.fit(X_train,Y_train)\n    rf_reg.predict(X_test)\n    score = rf_reg.score(X_test,Y_test)\n    if score > best_score:\n        best_score = score\n        a = max_depth\n        b = rf_reg.n_estimators\nprint((a,b))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  SVM","metadata":{}},{"cell_type":"markdown","source":"# Import two modules sklearn.datasets, and sklearn.model_selection.\n\nLoad popular digits dataset from sklearn.datasets module and assign it to variable digits.\n\nSplit digits.data into two sets names X_train and X_test. Also, split digits.target into two sets Y_train and Y_test.\n\nHint: Use train_test_split method from sklearn.model_selection; set random_state to 30; and perform stratified sampling.\nPrint the shape of X_train dataset.\n\nPrint the shape of X_test dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\ndigits = load_digits()\nX_train,X_test,Y_train,Y_test = train_test_split(digits.data,digits.target,random_state = 30,stratify = digits.target)\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 2\nImport required module from sklearn.svm.\n\nBuild an SVM classifier from X_train set and Y_train labels, with default parameters. Name the model as svm_clf.\n\nEvaluate the model accuracy on testing data set and print it's score.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\ndigits = load_digits()\nX_train,X_test,Y_train,Y_test = train_test_split(digits.data,digits.target,random_state = 30,stratify = digits.target)\nfrom sklearn.svm import SVC\nsvm_clf = SVC(gamma=\"auto\").fit(X_train,Y_train)\nprint(svm_clf.score(X_test,Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 3\nPerform Standardization of digits.data and store the transformed data in variable digits_standardized.\n\nHint : Use required utility from sklearn.preprocessing.\nOnce again, split digits_standardized into two sets names X_train and X_test. Also, split digits.target into two sets Y_train and Y_test.\n\nHint: Use train_test_split method from sklearn.model_selection; set random_state to 30; and perform stratified sampling.\nBuild another SVM classifier from X_train set and Y_train labels, with default parameters. Name the model as svm_clf2.\n\nEvaluate the model accuracy on testing data set and print it's score","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\ndigits = load_digits()\nfrom sklearn.preprocessing import StandardScaler\nstd_scale = StandardScaler().fit(digits.data)\ndigits_standardized = std_scale.transform(digits.data)\nX_train,X_test,Y_train,Y_test = train_test_split(digits_standardized,digits.target,random_state = 30,stratify = digits.target)\nfrom sklearn.svm import SVC\nsvm_clf2 = SVC(gamma=\"auto\").fit(X_train,Y_train)\nprint(svm_clf2.score(X_test,Y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 1\nImport three modules sklearn.datasets, sklearn.cluster, and sklearn.metrics.\n\nLoad popular iris dataset from sklearn.datasets module and assign it to variable iris.\n\nCluster iris.data set into 3 clusters using K-means with default parameters. Name the model as km_cls.\n\nHint : Import required utility from sklearn.cluster\nDetermine the homogeneity score of the model and print it.\n\nHint : Import required utility from sklearn.metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import homogeneity_score\nfrom sklearn.model_selection import train_test_split\niris = load_iris()\nX_train,X_test,Y_train,Y_test = train_test_split(iris.data,iris.target)\nkm_cls = KMeans(n_clusters=3)\nkm_cls.fit(X_train,Y_train)\nprint(homogeneity_score(km_cls.predict(X_test), Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 2\nCluster iris.data set into 3 clusters using Agglomerative clustering. Name the model as agg_cls.\n\nHint : Import required utility from sklearn.cluster\nDetermine the homogeneity score of the model and print it.\n\nHint : Import required utility from sklearn.metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\nfrom sklearn.datasets import load_iris\nfrom sklearn.metrics import homogeneity_score\nfrom sklearn.model_selection import train_test_split\niris = load_iris()\nX_train,X_test,Y_train,Y_test = train_test_split(iris.data,iris.target)\nagg_cls = AgglomerativeClustering(n_clusters=3)\nagg_cls .fit(X_train,Y_train)\nprint(homogeneity_score(agg_cls .fit_predict(X_test), Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.preprocessing as preprocessing\n\nregions = ['HYD', 'CHN', 'MUM', 'HYD', 'KOL', 'CHN']\nprint(preprocessing.LabelEncoder().fit(regions).transform(regions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfig = plt.figure()\ngs = gridspec.GridSpec(3, 3)\nax1 = plt.subplot(gs[0, :])\nax2 = plt.subplot(gs[1, :-1])\nax3 = plt.subplot(gs[1:, -1])\nax4 = plt.subplot(gs[-1, 0])\nax5 = plt.subplot(gs[-1, -2])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111, title=\"My Plot\")\nx = [0, 1, 2, 3, 4]\ny = [0, 3, 6, 9, 12]\nplt.scatter(x, y, s=[20, 60], c=['r', 'g'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.preprocessing as preprocessing\n\nx = [[7.8], [1.3], [4.5], [0.9]]\nprint(preprocessing.Binarizer().fit(x).transform(x).shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.preprocessing as preprocessing\n\nx = [[7.8], [1.3], [4.5], [0.9]]\nprint(preprocessing.Binarizer().fit(x).transform(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.gridspec as gridspec\nfig = plt.figure()\ngs = gridspec.GridSpec(3, 3)\nax1 = plt.subplot(gs[:2, :2])\nax2 = plt.subplot(gs[0, 2])\nax3 = plt.subplot(gs[1, 2])\nax4 = plt.subplot(gs[-1, 0])\nax5 = plt.subplot(gs[-1, 1:])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111)\nplt.plot([10, 12, 14, 16])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}